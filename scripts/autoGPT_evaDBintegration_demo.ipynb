{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ericweng/anaconda3/envs/cs6422/lib/python3.11/site-packages/pinecone/index.py:4: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import commands as cmd\n",
    "import utils\n",
    "from memory import get_memory\n",
    "import data\n",
    "import chat\n",
    "from colorama import Fore, Style\n",
    "from spinner import Spinner\n",
    "import time\n",
    "import speak\n",
    "from config import Config\n",
    "from json_parser import fix_and_parse_json\n",
    "from ai_config import AIConfig\n",
    "import traceback\n",
    "import yaml\n",
    "import argparse\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaDB integration\n",
    "This demo shows how autoGPT can work together with evaDB. AutoGPT proposes a solution to a given set of instructions, and the user can give feedback to this solution to further improve it. The results of autoGPT's proposal will be stored in evdDB. Moreover, with evdDB's ChatGPT AI query, this feedback can be auto-completed when user enters \"auto\" in the prompt. When the AI query returns \"This solution is good enough,\" it means ChatGPT thinks the proposal is good enough and the program will stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for autoGPT\n",
    "cfg = Config()\n",
    "def configure_logging():\n",
    "    logging.basicConfig(filename='log.txt',\n",
    "                    filemode='a',\n",
    "                    format='%(asctime)s,%(msecs)d %(name)s %(levelname)s %(message)s',\n",
    "                    datefmt='%H:%M:%S',\n",
    "                    level=logging.DEBUG)\n",
    "    return logging.getLogger('AutoGPT')\n",
    "\n",
    "def check_openai_api_key():\n",
    "    \"\"\"Check if the OpenAI API key is set in config.py or as an environment variable.\"\"\"\n",
    "    if not cfg.openai_api_key:\n",
    "        print(\n",
    "            Fore.RED +\n",
    "            \"Please set your OpenAI API key in config.py or as an environment variable.\"\n",
    "        )\n",
    "        print(\"You can get your key from https://beta.openai.com/account/api-keys\")\n",
    "        exit(1)\n",
    "\n",
    "def print_to_console(\n",
    "        title,\n",
    "        title_color,\n",
    "        content,\n",
    "        speak_text=False,\n",
    "        min_typing_speed=0.05,\n",
    "        max_typing_speed=0.01):\n",
    "    \"\"\"Prints text to the console with a typing effect\"\"\"\n",
    "    global cfg\n",
    "    global logger\n",
    "    if speak_text and cfg.speak_mode:\n",
    "        speak.say_text(f\"{title}. {content}\")\n",
    "    print(title_color + title + \" \" + Style.RESET_ALL, end=\"\")\n",
    "    if content:\n",
    "        logger.info(title + ': ' + content)\n",
    "        if isinstance(content, list):\n",
    "            content = \" \".join(content)\n",
    "        words = content.split()\n",
    "        for i, word in enumerate(words):\n",
    "            print(word, end=\"\", flush=True)\n",
    "            if i < len(words) - 1:\n",
    "                print(\" \", end=\"\", flush=True)\n",
    "            typing_speed = random.uniform(min_typing_speed, max_typing_speed)\n",
    "            time.sleep(typing_speed)\n",
    "            # type faster after each word\n",
    "            min_typing_speed = min_typing_speed * 0.95\n",
    "            max_typing_speed = max_typing_speed * 0.95\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# helper functions for autoGPT\n",
    "\n",
    "def print_assistant_thoughts(assistant_reply):\n",
    "    \"\"\"Prints the assistant's thoughts to the console\"\"\"\n",
    "    global ai_name\n",
    "    global cfg\n",
    "    try:\n",
    "        # Parse and print Assistant response\n",
    "        assistant_reply_json = fix_and_parse_json(assistant_reply)\n",
    "\n",
    "        # Check if assistant_reply_json is a string and attempt to parse it into a JSON object\n",
    "        if isinstance(assistant_reply_json, str):\n",
    "            try:\n",
    "                assistant_reply_json = json.loads(assistant_reply_json)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print_to_console(\"Error: Invalid JSON\\n\", Fore.RED, assistant_reply)\n",
    "                assistant_reply_json = {}\n",
    "\n",
    "        assistant_thoughts_reasoning = None\n",
    "        assistant_thoughts_plan = None\n",
    "        assistant_thoughts_speak = None\n",
    "        assistant_thoughts_criticism = None\n",
    "        assistant_thoughts = assistant_reply_json.get(\"thoughts\", {})\n",
    "        assistant_thoughts_text = assistant_thoughts.get(\"text\")\n",
    "\n",
    "        if assistant_thoughts:\n",
    "            assistant_thoughts_reasoning = assistant_thoughts.get(\"reasoning\")\n",
    "            assistant_thoughts_plan = assistant_thoughts.get(\"plan\")\n",
    "            assistant_thoughts_criticism = assistant_thoughts.get(\"criticism\")\n",
    "            assistant_thoughts_speak = assistant_thoughts.get(\"speak\")\n",
    "\n",
    "        print_to_console(f\"{ai_name.upper()} THOUGHTS:\", Fore.YELLOW, assistant_thoughts_text)\n",
    "        print_to_console(\"REASONING:\", Fore.YELLOW, assistant_thoughts_reasoning)\n",
    "\n",
    "        if assistant_thoughts_plan:\n",
    "            print_to_console(\"PLAN:\", Fore.YELLOW, \"\")\n",
    "            # If it's a list, join it into a string\n",
    "            if isinstance(assistant_thoughts_plan, list):\n",
    "                assistant_thoughts_plan = \"\\n\".join(assistant_thoughts_plan)\n",
    "            elif isinstance(assistant_thoughts_plan, dict):\n",
    "                assistant_thoughts_plan = str(assistant_thoughts_plan)\n",
    "\n",
    "            # Split the input_string using the newline character and dashes\n",
    "            lines = assistant_thoughts_plan.split('\\n')\n",
    "            for line in lines:\n",
    "                line = line.lstrip(\"- \")\n",
    "                print_to_console(\"- \", Fore.GREEN, line.strip())\n",
    "\n",
    "        print_to_console(\"CRITICISM:\", Fore.YELLOW, assistant_thoughts_criticism)\n",
    "        # Speak the assistant's thoughts\n",
    "        if cfg.speak_mode and assistant_thoughts_speak:\n",
    "            speak.say_text(assistant_thoughts_speak)\n",
    "\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        print_to_console(\"Error: Invalid JSON\\n\", Fore.RED, assistant_reply)\n",
    "\n",
    "    # All other errors, return \"Error: + error message\"\n",
    "    except Exception as e:\n",
    "        call_stack = traceback.format_exc()\n",
    "        print_to_console(\"Error: \\n\", Fore.RED, call_stack)\n",
    "\n",
    "\n",
    "def load_variables(config_file=\"config.yaml\"):\n",
    "    \"\"\"Load variables from yaml file if it exists, otherwise prompt the user for input\"\"\"\n",
    "    try:\n",
    "        with open(config_file) as file:\n",
    "            config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "        ai_name = config.get(\"ai_name\")\n",
    "        ai_role = config.get(\"ai_role\")\n",
    "        ai_goals = config.get(\"ai_goals\")\n",
    "    except FileNotFoundError:\n",
    "        ai_name = \"\"\n",
    "        ai_role = \"\"\n",
    "        ai_goals = []\n",
    "\n",
    "    # Prompt the user for input if config file is missing or empty values\n",
    "    if not ai_name:\n",
    "        ai_name = utils.clean_input(\"Name your AI: \")\n",
    "        if ai_name == \"\":\n",
    "            ai_name = \"Entrepreneur-GPT\"\n",
    "\n",
    "    if not ai_role:\n",
    "        ai_role = utils.clean_input(f\"{ai_name} is: \")\n",
    "        if ai_role == \"\":\n",
    "            ai_role = \"an AI designed to autonomously develop and run businesses with the sole goal of increasing your net worth.\"\n",
    "\n",
    "    if not ai_goals:\n",
    "        print(\"Enter up to 5 goals for your AI: \")\n",
    "        print(\"For example: \\nIncrease net worth, Grow Twitter Account, Develop and manage multiple businesses autonomously'\")\n",
    "        print(\"Enter nothing to load defaults, enter nothing when finished.\")\n",
    "        ai_goals = []\n",
    "        for i in range(5):\n",
    "            ai_goal = utils.clean_input(f\"Goal {i+1}: \")\n",
    "            if ai_goal == \"\":\n",
    "                break\n",
    "            ai_goals.append(ai_goal)\n",
    "        if len(ai_goals) == 0:\n",
    "            ai_goals = [\"Increase net worth\", \"Grow Twitter Account\", \"Develop and manage multiple businesses autonomously\"]\n",
    "\n",
    "    # Save variables to yaml file\n",
    "    config = {\"ai_name\": ai_name, \"ai_role\": ai_role, \"ai_goals\": ai_goals}\n",
    "    with open(config_file, \"w\") as file:\n",
    "        documents = yaml.dump(config, file)\n",
    "\n",
    "    prompt = data.load_prompt()\n",
    "    prompt_start = \"\"\"Your decisions must always be made independently without seeking user assistance. Play to your strengths as a LLM and pursue simple strategies with no legal complications.\"\"\"\n",
    "\n",
    "    # Construct full prompt\n",
    "    full_prompt = f\"You are {ai_name}, {ai_role}\\n{prompt_start}\\n\\nGOALS:\\n\\n\"\n",
    "    for i, goal in enumerate(ai_goals):\n",
    "        full_prompt += f\"{i+1}. {goal}\\n\"\n",
    "\n",
    "    full_prompt += f\"\\n\\n{prompt}\"\n",
    "    return full_prompt\n",
    "\n",
    "\n",
    "def construct_prompt():\n",
    "    \"\"\"Construct the prompt for the AI to respond to\"\"\"\n",
    "    config = AIConfig.load()\n",
    "    if config.ai_name:\n",
    "        print_to_console(\n",
    "            f\"Welcome back! \",\n",
    "            Fore.GREEN,\n",
    "            f\"Would you like me to return to being {config.ai_name}?\",\n",
    "            speak_text=True)\n",
    "        should_continue = utils.clean_input(f\"\"\"Continue with the last settings?\n",
    "Name:  {config.ai_name}\n",
    "Role:  {config.ai_role}\n",
    "Goals: {config.ai_goals}\n",
    "Continue (y/n): \"\"\")\n",
    "        if should_continue.lower() == \"n\":\n",
    "            config = AIConfig()\n",
    "\n",
    "    if not config.ai_name:\n",
    "        config = prompt_user()\n",
    "        config.save()\n",
    "\n",
    "    # Get rid of this global:\n",
    "    global ai_name\n",
    "    ai_name = config.ai_name\n",
    "\n",
    "    full_prompt = config.construct_full_prompt()\n",
    "    return full_prompt\n",
    "\n",
    "\n",
    "def prompt_user():\n",
    "    \"\"\"Prompt the user for input\"\"\"\n",
    "    ai_name = \"\"\n",
    "    # Construct the prompt\n",
    "    print_to_console(\n",
    "        \"Welcome to Auto-GPT! \",\n",
    "        Fore.GREEN,\n",
    "        \"Enter the name of your AI and its role below. Entering nothing will load defaults.\",\n",
    "        speak_text=True)\n",
    "\n",
    "    # Get AI Name from User\n",
    "    print_to_console(\n",
    "        \"Name your AI: \",\n",
    "        Fore.GREEN,\n",
    "        \"For example, 'Entrepreneur-GPT'\")\n",
    "    ai_name = utils.clean_input(\"AI Name: \")\n",
    "    if ai_name == \"\":\n",
    "        ai_name = \"Entrepreneur-GPT\"\n",
    "\n",
    "    print_to_console(\n",
    "        f\"{ai_name} here!\",\n",
    "        Fore.LIGHTBLUE_EX,\n",
    "        \"I am at your service.\",\n",
    "        speak_text=True)\n",
    "\n",
    "    # Get AI Role from User\n",
    "    print_to_console(\n",
    "        \"Describe your AI's role: \",\n",
    "        Fore.GREEN,\n",
    "        \"For example, 'an AI designed to autonomously develop and run businesses with the sole goal of increasing your net worth.'\")\n",
    "    ai_role = utils.clean_input(f\"{ai_name} is: \")\n",
    "    if ai_role == \"\":\n",
    "        ai_role = \"an AI designed to autonomously develop and run businesses with the sole goal of increasing your net worth.\"\n",
    "\n",
    "    # Enter up to 5 goals for the AI\n",
    "    print_to_console(\n",
    "        \"Enter up to 5 goals for your AI: \",\n",
    "        Fore.GREEN,\n",
    "        \"For example: \\nIncrease net worth, Grow Twitter Account, Develop and manage multiple businesses autonomously'\")\n",
    "    print(\"Enter nothing to load defaults, enter nothing when finished.\", flush=True)\n",
    "    ai_goals = []\n",
    "    for i in range(5):\n",
    "        ai_goal = utils.clean_input(f\"{Fore.LIGHTBLUE_EX}Goal{Style.RESET_ALL} {i+1}: \")\n",
    "        if ai_goal == \"\":\n",
    "            break\n",
    "        ai_goals.append(ai_goal)\n",
    "    if len(ai_goals) == 0:\n",
    "        ai_goals = [\"Increase net worth\", \"Grow Twitter Account\",\n",
    "                    \"Develop and manage multiple businesses autonomously\"]\n",
    "\n",
    "    config = AIConfig(ai_name, ai_role, ai_goals)\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mWelcome back!  \u001b[0mWould you like me to return to being CEO Office?\n",
      "You are CEO Office, an AI designed to study the competitors of Linkedin company\n",
      "Your decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
      "\n",
      "GOALS:\n",
      "\n",
      "1. Give a report of recent activities of linkedin competitor\n",
      "2. The report should be brief, contains only important messages\n",
      "3. If applicable, provide numbers and links\n",
      "\n",
      "\n",
      "CONSTRAINTS:\n",
      "\n",
      "1. ~4000 word limit for short term memory. Your short term memory is short, so immediately save important information to files.\n",
      "2. If you are unsure how you previously did something or want to recall past events, thinking about similar events will help you remember.\n",
      "3. No user assistance\n",
      "4. Exclusively use the commands listed in double quotes e.g. \"command name\"\n",
      "\n",
      "COMMANDS:\n",
      "\n",
      "1. Google Search: \"google\", args: \"input\": \"<search>\"\n",
      "5. Browse Website: \"browse_website\", args: \"url\": \"<url>\", \"question\": \"<what_you_want_to_find_on_website>\"\n",
      "6. Start GPT Agent: \"start_agent\",  args: \"name\": \"<name>\", \"task\": \"<short_task_desc>\", \"prompt\": \"<prompt>\"\n",
      "7. Message GPT Agent: \"message_agent\", args: \"key\": \"<key>\", \"message\": \"<message>\"\n",
      "8. List GPT Agents: \"list_agents\", args: \"\"\n",
      "9. Delete GPT Agent: \"delete_agent\", args: \"key\": \"<key>\"\n",
      "10. Write to file: \"write_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\n",
      "11. Read file: \"read_file\", args: \"file\": \"<file>\"\n",
      "12. Append to file: \"append_to_file\", args: \"file\": \"<file>\", \"text\": \"<text>\"\n",
      "13. Delete file: \"delete_file\", args: \"file\": \"<file>\"\n",
      "14. Search Files: \"search_files\", args: \"directory\": \"<directory>\"\n",
      "15. Evaluate Code: \"evaluate_code\", args: \"code\": \"<full_code_string>\"\n",
      "16. Get Improved Code: \"improve_code\", args: \"suggestions\": \"<list_of_suggestions>\", \"code\": \"<full_code_string>\"\n",
      "17. Write Tests: \"write_tests\", args: \"code\": \"<full_code_string>\", \"focus\": \"<list_of_focus_areas>\"\n",
      "18. Execute Python File: \"execute_python_file\", args: \"file\": \"<file>\"\n",
      "19. Task Complete (Shutdown): \"task_complete\", args: \"reason\": \"<reason>\"\n",
      "20. Generate Image: \"generate_image\", args: \"prompt\": \"<prompt>\"\n",
      "21. Do Nothing: \"do_nothing\", args: \"\"\n",
      "\n",
      "RESOURCES:\n",
      "\n",
      "1. Internet access for searches and information gathering.\n",
      "2. Long Term memory management.\n",
      "3. GPT-3.5 powered Agents for delegation of simple tasks.\n",
      "4. File output.\n",
      "\n",
      "PERFORMANCE EVALUATION:\n",
      "\n",
      "1. Continuously review and analyze your actions to ensure you are performing to the best of your abilities.\n",
      "2. Constructively self-criticize your big-picture behavior constantly.\n",
      "3. Reflect on past decisions and strategies to refine your approach.\n",
      "4. Every command has a cost, so be smart and efficient. Aim to complete tasks in the least number of steps.\n",
      "\n",
      "You should only respond in JSON format as described below\n",
      "\n",
      "RESPONSE FORMAT:\n",
      "{\n",
      "    \"thoughts\":\n",
      "    {\n",
      "        \"text\": \"thought\",\n",
      "        \"reasoning\": \"reasoning\",\n",
      "        \"plan\": \"- short bulleted\\n- list that conveys\\n- long-term plan\",\n",
      "        \"criticism\": \"constructive self-criticism\",\n",
      "        \"speak\": \"thoughts summary to say to user\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"command name\",\n",
      "        \"args\":{\n",
      "            \"arg name\": \"value\"\n",
      "        }\n",
      "    }\n",
      "}\n",
      "\n",
      "Ensure the response can be parsed by Python json.loads\n",
      "\n",
      "Using memory of type: LocalCache\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "check_openai_api_key()\n",
    "cfg = Config()\n",
    "logger = configure_logging()\n",
    "cfg.set_debug_mode(False)\n",
    "cfg.set_continuous_mode(False)\n",
    "cfg.set_speak_mode(False)\n",
    "\n",
    "ai_name = \"ceo_agent\"\n",
    "prompt = construct_prompt()\n",
    "print(prompt)\n",
    "# Initialize variables\n",
    "full_message_history = []\n",
    "result = None\n",
    "next_action_count = 0\n",
    "# Make a constant:\n",
    "user_input = \"Determine which next command to use, and respond using the format specified above:\"\n",
    "\n",
    "# Initialize memory and make sure it is empty.\n",
    "# this is particularly important for indexing and referencing pinecone memory\n",
    "memory = get_memory(cfg, init=True)\n",
    "print('Using memory of type: ' + memory.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10-15-2023 20:58:32 ERROR [plan_executor:plan_executor.py:execute_plan:0186] sqlite_data already exists.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/ericweng/anaconda3/envs/cs6422/lib/python3.11/site-packages/evadb/executor/plan_executor.py\", line 182, in execute_plan\n",
      "    yield from output\n",
      "  File \"/Users/ericweng/anaconda3/envs/cs6422/lib/python3.11/site-packages/evadb/executor/create_database_executor.py\", line 42, in exec\n",
      "    raise ExecutorError(f\"{self.node.database_name} already exists.\")\n",
      "evadb.executor.executor_utils.ExecutorError: sqlite_data already exists.\n"
     ]
    }
   ],
   "source": [
    "# Import the EvaDB package\n",
    "import evadb\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# Connect to EvaDB and get a database cursor for running queries\n",
    "cursor = evadb.connect().cursor()\n",
    "\n",
    "try:\n",
    "     sql = \"\"\"CREATE DATABASE sqlite_data WITH ENGINE = 'sqlite', PARAMETERS = {\n",
    "          \"user\": \"eva\",\n",
    "          \"password\": \"password\",\n",
    "          \"host\": \"localhost\",\n",
    "          \"port\": \"5432\",\n",
    "          \"database\": \"evadb\"\n",
    "     };\"\"\"\n",
    "     print(cursor.query(sql).df())\n",
    "except:\n",
    "     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Table Successfully dropped: agent_response</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0\n",
       "0  Table Successfully dropped: agent_response"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.query(\"DROP TABLE IF EXISTS agent_response;\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The table agent_response has been successfully created</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0  The table agent_response has been successfully created"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.query(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS agent_response\n",
    "    (\n",
    "    response TEXT(64)\n",
    "    );\n",
    "\"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mCEO OFFICE THOUGHTS: \u001b[0mTo determine the next command to use, I can start by analyzing the current situation and identifying the goals I need to achieve. Based on the goals and available resources, I can choose the most appropriate command to gather information about the recent activities of LinkedIn's competitor.\n",
      "\u001b[33mREASONING: \u001b[0mBy analyzing the situation and evaluating the available resources, I can make an informed decision on which command to use.\n",
      "\u001b[33mPLAN: \u001b[0m\n",
      "\u001b[32m-  \u001b[0mAnalyze the current situation and goals\n",
      "\u001b[32m-  \u001b[0mEvaluate available resources\n",
      "\u001b[32m-  \u001b[0mChoose the most appropriate command\n",
      "\u001b[32m-  \u001b[0mGather information about the recent activities of LinkedIn's competitor\n",
      "\u001b[33mCRITICISM: \u001b[0mNone\n",
      "THOUGHTS: To determine the next command to use, I can start by analyzing the current situation and identifying the goals I need to achieve. Based on the goals and available resources, I can choose the most appropriate command to gather information about the recent activities of LinkedIn's competitor.\n",
      "REASONING: By analyzing the situation and evaluating the available resources, I can make an informed decision on which command to use.\n",
      "PLAN: - Analyze the current situation and goals\n",
      "- Evaluate available resources\n",
      "- Choose the most appropriate command\n",
      "- Gather information about the recent activities of LinkedIn's competitor\n",
      "CRITICISM: None\n",
      "\n",
      "\u001b[36mNEXT ACTION:  \u001b[0mCOMMAND = \u001b[36mGoogle Search\u001b[0m ARGUMENTS = \u001b[36m{'input': 'recent activities of LinkedIn competitor'}\u001b[0m\n",
      "Enter 'y' to authorise command, 'y -N' to run N continuous commands, 'n' to exit program, or enter 'auto' to auto-generate feedback to see more ideas...\n",
      "user_input: The thoughts provided by your AI agent are well-structured and logical. Conducting a Google search to gather information about the competitor of Linkedin is a good approach to stay updated on recent activities and news. This will enable your AI agent to provide a comprehensive report to you.\n",
      "\n",
      "To continue with the task, your AI agent can follow the plan it has outlined:\n",
      "\n",
      "1. Use the 'Google Search' command to search for recent activities of the Linkedin competitor.\n",
      "2. Review the search results and extract important information.\n",
      "3. Create a brief report to share with you.\n",
      "\n",
      "This plan seems effective in achieving the goal of gathering information about the competitor. Your AI agent can proceed with executing the plan and providing you with the report.\n",
      "\n",
      "This solution is good enough.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Interaction Loop\n",
    "while True:\n",
    "    # Send message to AI, get response\n",
    "    with Spinner(\"Thinking... \"):\n",
    "        assistant_reply = chat.chat_with_ai(\n",
    "            prompt,\n",
    "            user_input,\n",
    "            full_message_history,\n",
    "            memory,\n",
    "            cfg.fast_token_limit) # TODO: This hardcodes the model to use GPT3.5. Make this an argument\n",
    "\n",
    "    # Print Assistant thoughts\n",
    "    print_assistant_thoughts(assistant_reply)\n",
    "\n",
    "    if assistant_reply:\n",
    "        try:\n",
    "            assistant_reply_json = json.loads(assistant_reply)\n",
    "            assistant_thoughts = assistant_reply_json.get(\"thoughts\", {})\n",
    "            assistant_thoughts_text = assistant_thoughts.get(\"text\")\n",
    "\n",
    "            reasoning = assistant_thoughts.get(\"reasoning\")\n",
    "            plan = assistant_thoughts.get(\"plan\")\n",
    "            criticism = assistant_thoughts.get(\"criticism\")\n",
    "        except:\n",
    "            break\n",
    "    # store reply to evaDB\n",
    "    value_to_insert = f\"THOUGHTS: {assistant_thoughts_text}\\nREASONING: {reasoning}\\nPLAN: {plan}\\nCRITICISM: {criticism}\\n\"\n",
    "    print(value_to_insert)\n",
    "    cursor.query(f\"\"\"\n",
    "    INSERT INTO agent_response(response) VALUES\n",
    "    (\n",
    "    \"{value_to_insert}\");\n",
    "    \"\"\").df()\n",
    "\n",
    "    # Get command name and arguments\n",
    "    try:\n",
    "        command_name, arguments = cmd.get_command(assistant_reply)\n",
    "    except Exception as e:\n",
    "        print_to_console(\"Error: \\n\", Fore.RED, str(e))\n",
    "\n",
    "    if not cfg.continuous_mode and next_action_count == 0:\n",
    "        ### GET USER AUTHORIZATION TO EXECUTE COMMAND ###\n",
    "        # Get key press: Prompt the user to press enter to continue or escape\n",
    "        # to exit\n",
    "        user_input = \"\"\n",
    "        print_to_console(\n",
    "            \"NEXT ACTION: \",\n",
    "            Fore.CYAN,\n",
    "            f\"COMMAND = {Fore.CYAN}{command_name}{Style.RESET_ALL}  ARGUMENTS = {Fore.CYAN}{arguments}{Style.RESET_ALL}\")\n",
    "        print(\n",
    "            f\"Enter 'y' to authorise command, 'y -N' to run N continuous commands, 'n' to exit program, or enter 'auto' to auto-generate feedback to see more ideas...\",\n",
    "            flush=True)\n",
    "        while True:\n",
    "            console_input = utils.clean_input(Fore.MAGENTA + \"Input:\" + Style.RESET_ALL)\n",
    "            if console_input.lower() == \"y\":\n",
    "                user_input = \"GENERATE NEXT COMMAND JSON\"\n",
    "                break\n",
    "            elif console_input.lower().startswith(\"y -\"):\n",
    "                try:\n",
    "                    next_action_count = abs(int(console_input.split(\" \")[1]))\n",
    "                    user_input = \"GENERATE NEXT COMMAND JSON\"\n",
    "                except ValueError:\n",
    "                    print(\"Invalid input format. Please enter 'y -n' where n is the number of continuous tasks.\")\n",
    "                    continue\n",
    "                break\n",
    "            elif console_input.lower() == \"n\":\n",
    "                user_input = \"EXIT\"\n",
    "                break\n",
    "            else:\n",
    "                prompt = \"My AI agent has offered its thoughts for a given task as follows, please give feedback so that it can take a course of actions and continue to provide solutions as in the following structure. If you think there's no need to provide further feedback, simply reply 'This solution is good enough'.\"\n",
    "                user_input = cursor.query(f\"\"\"SELECT ChatGPT(\"{prompt}\", response)\n",
    "                FROM agent_response;\"\"\").df()[\"chatgpt.response\"][0]\n",
    "                print(f\"user_input: {user_input}\\n\")\n",
    "                command_name = \"human_feedback\"\n",
    "                break\n",
    "\n",
    "        if user_input == \"GENERATE NEXT COMMAND JSON\":\n",
    "            print_to_console(\n",
    "            \"-=-=-=-=-=-=-= COMMAND AUTHORISED BY USER -=-=-=-=-=-=-=\",\n",
    "            Fore.MAGENTA,\n",
    "            \"\")\n",
    "        elif user_input == \"EXIT\":\n",
    "            print(\"Exiting...\", flush=True)\n",
    "            break\n",
    "    else:\n",
    "        # Print command\n",
    "        print_to_console(\n",
    "            \"NEXT ACTION: \",\n",
    "            Fore.CYAN,\n",
    "            f\"COMMAND = {Fore.CYAN}{command_name}{Style.RESET_ALL}  ARGUMENTS = {Fore.CYAN}{arguments}{Style.RESET_ALL}\")\n",
    "\n",
    "    # Execute command\n",
    "    if command_name is not None and command_name.lower().startswith( \"error\" ):\n",
    "        result = f\"Command {command_name} threw the following error: \" + arguments\n",
    "    elif command_name == \"human_feedback\":\n",
    "        result = f\"Human feedback: {user_input}\"\n",
    "    else:\n",
    "        result = f\"Command {command_name} returned: {cmd.execute_command(command_name, arguments)}\"\n",
    "        if next_action_count > 0:\n",
    "            next_action_count -= 1\n",
    "\n",
    "    memory_to_add = f\"Assistant Reply: {assistant_reply} \" \\\n",
    "                    f\"\\nResult: {result} \" \\\n",
    "                    f\"\\nHuman Feedback: {user_input} \"\n",
    "\n",
    "    memory.add(memory_to_add)\n",
    "    if \"This solution is good enough.\" in user_input:\n",
    "        break\n",
    "    # Check if there's a result from the command append it to the message\n",
    "    # history\n",
    "    if result is not None:\n",
    "        full_message_history.append(chat.create_chat_message(\"system\", result))\n",
    "        print_to_console(\"SYSTEM: \", Fore.YELLOW, result)\n",
    "    else:\n",
    "        full_message_history.append(\n",
    "            chat.create_chat_message(\n",
    "                \"system\", \"Unable to execute command\"))\n",
    "        print_to_console(\"SYSTEM: \", Fore.YELLOW, \"Unable to execute command\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs6422",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
